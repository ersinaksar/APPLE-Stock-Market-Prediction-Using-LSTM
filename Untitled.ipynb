{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "220e8bf3",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfda9be",
   "metadata": {},
   "source": [
    "CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b78eab",
   "metadata": {},
   "source": [
    "Temizleme "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e23589",
   "metadata": {},
   "source": [
    "Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d49dcf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veri okumak için kütüphane\n",
    "from pandas_datareader.data import DataReader\n",
    "#zaman işlemleri için kütüphane\n",
    "from datetime import datetime\n",
    "from pandas_datareader import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ccb88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataReader('AAPL', data_source = 'yahoo', start = '2012-01-01', end = datetime.now() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccd564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f6499",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"AAPL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477a7f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc98ef",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot('High', 'Close', df, kind = 'scatter', color ='darkblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a423c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot('Open', 'Close', df, kind = 'reg', color ='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa574dd",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d376bd6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df, kind = 'reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8f86a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas versiyonu: 1.1.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"pandas versiyonu: {}\".format(pd.__version__))\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cf6556c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.732143</td>\n",
       "      <td>14.607143</td>\n",
       "      <td>14.621429</td>\n",
       "      <td>14.686786</td>\n",
       "      <td>302220800.0</td>\n",
       "      <td>12.629209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.810000</td>\n",
       "      <td>14.617143</td>\n",
       "      <td>14.642857</td>\n",
       "      <td>14.765714</td>\n",
       "      <td>260022000.0</td>\n",
       "      <td>12.697079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.948214</td>\n",
       "      <td>14.738214</td>\n",
       "      <td>14.819643</td>\n",
       "      <td>14.929643</td>\n",
       "      <td>271269600.0</td>\n",
       "      <td>12.838044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.098214</td>\n",
       "      <td>14.972143</td>\n",
       "      <td>14.991786</td>\n",
       "      <td>15.085714</td>\n",
       "      <td>318292800.0</td>\n",
       "      <td>12.972249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.276786</td>\n",
       "      <td>15.048214</td>\n",
       "      <td>15.196429</td>\n",
       "      <td>15.061786</td>\n",
       "      <td>394024400.0</td>\n",
       "      <td>12.951672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>132.410004</td>\n",
       "      <td>129.210007</td>\n",
       "      <td>130.300003</td>\n",
       "      <td>132.300003</td>\n",
       "      <td>79663300.0</td>\n",
       "      <td>132.300003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>134.080002</td>\n",
       "      <td>131.619995</td>\n",
       "      <td>132.130005</td>\n",
       "      <td>133.979996</td>\n",
       "      <td>74783600.0</td>\n",
       "      <td>133.979996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>134.320007</td>\n",
       "      <td>133.229996</td>\n",
       "      <td>133.770004</td>\n",
       "      <td>133.699997</td>\n",
       "      <td>60214200.0</td>\n",
       "      <td>133.699997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>134.639999</td>\n",
       "      <td>132.929993</td>\n",
       "      <td>134.449997</td>\n",
       "      <td>133.410004</td>\n",
       "      <td>68711000.0</td>\n",
       "      <td>133.410004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>133.889999</td>\n",
       "      <td>132.809998</td>\n",
       "      <td>133.460007</td>\n",
       "      <td>133.110001</td>\n",
       "      <td>70730700.0</td>\n",
       "      <td>133.110001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2386 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            High         Low        Open       Close       Volume   Adj Close\n",
       "0      14.732143   14.607143   14.621429   14.686786  302220800.0   12.629209\n",
       "1      14.810000   14.617143   14.642857   14.765714  260022000.0   12.697079\n",
       "2      14.948214   14.738214   14.819643   14.929643  271269600.0   12.838044\n",
       "3      15.098214   14.972143   14.991786   15.085714  318292800.0   12.972249\n",
       "4      15.276786   15.048214   15.196429   15.061786  394024400.0   12.951672\n",
       "...          ...         ...         ...         ...          ...         ...\n",
       "2381  132.410004  129.210007  130.300003  132.300003   79663300.0  132.300003\n",
       "2382  134.080002  131.619995  132.130005  133.979996   74783600.0  133.979996\n",
       "2383  134.320007  133.229996  133.770004  133.699997   60214200.0  133.699997\n",
       "2384  134.639999  132.929993  134.449997  133.410004   68711000.0  133.410004\n",
       "2385  133.889999  132.809998  133.460007  133.110001   70730700.0  133.110001\n",
       "\n",
       "[2386 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"AAPL.csv\"\n",
    "df = pd.read_csv(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0de40c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2386"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_rows = df[\"High\"].values\n",
    "len(lstm_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4d23da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2267"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_training_lata_len = int(np.ceil(len(lstm_rows) * .95))\n",
    "lstm_training_lata_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4081bbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2267"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "lstm_train_in_seq1 = df.iloc[0:int(lstm_training_lata_len),0:1].values #high\n",
    "lstm_train_in_seq2 = df.iloc[0:int(lstm_training_lata_len),1:2].values #low\n",
    "lstm_train_in_seq3 = df.iloc[0:int(lstm_training_lata_len),2:3].values #open\n",
    "lstm_train_out_seq = df.iloc[0:int(lstm_training_lata_len),3:4].values #close\n",
    "len(lstm_train_in_seq1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96ed8f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "lstm_test_in_seq1 = df.iloc[lstm_training_lata_len -60: ,0:1].values #high\n",
    "lstm_test_in_seq2 = df.iloc[lstm_training_lata_len -60:,1:2].values #low\n",
    "lstm_test_in_seq3 = df.iloc[lstm_training_lata_len -60:,2:3].values #open\n",
    "lstm_test_out_seq = df.iloc[lstm_training_lata_len -60:,3:4].values #close\n",
    "len(lstm_test_in_seq1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7225bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train boyutlandırma\n",
    "lstm_train_in_seq1 = lstm_train_in_seq1.reshape((len(lstm_train_in_seq1),1))\n",
    "lstm_train_in_seq2 = lstm_train_in_seq2.reshape((len(lstm_train_in_seq1),1))\n",
    "lstm_train_in_seq3 = lstm_train_in_seq3.reshape((len(lstm_train_in_seq1),1))\n",
    "lstm_train_out_seq = lstm_train_out_seq.reshape((len(lstm_train_in_seq1),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "685a71b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test boyutlandırma\n",
    "lstm_test_in_seq1 = lstm_test_in_seq1.reshape((len(lstm_test_in_seq1),1))\n",
    "lstm_test_in_seq2 = lstm_test_in_seq2.reshape((len(lstm_test_in_seq1),1))\n",
    "lstm_test_in_seq3 = lstm_test_in_seq3.reshape((len(lstm_test_in_seq1),1))\n",
    "lstm_test_out_seq = lstm_test_out_seq.reshape((len(lstm_test_in_seq1),1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aab30578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import hstack\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ef4d6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 14.7321434 ,  14.6071434 ,  14.62142944,  14.6867857 ],\n",
       "       [ 14.81000042,  14.61714268,  14.6428566 ,  14.76571369],\n",
       "       [ 14.94821358,  14.73821354,  14.81964302,  14.92964268],\n",
       "       ...,\n",
       "       [134.74000549, 131.72000122, 134.08000183, 132.69000244],\n",
       "       [133.61000061, 126.76000214, 133.52000427, 129.41000366],\n",
       "       [131.74000549, 128.42999268, 128.88999939, 131.00999451]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = hstack((lstm_train_in_seq1,lstm_train_in_seq2,lstm_train_in_seq3,lstm_train_out_seq))\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49bb7c23",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>131.740005</td>\n",
       "      <td>128.429993</td>\n",
       "      <td>128.889999</td>\n",
       "      <td>131.009995</td>\n",
       "      <td>97664900.0</td>\n",
       "      <td>130.592697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>131.050003</td>\n",
       "      <td>126.379997</td>\n",
       "      <td>127.720001</td>\n",
       "      <td>126.599998</td>\n",
       "      <td>155088000.0</td>\n",
       "      <td>126.196747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>131.630005</td>\n",
       "      <td>127.860001</td>\n",
       "      <td>128.360001</td>\n",
       "      <td>130.919998</td>\n",
       "      <td>109578200.0</td>\n",
       "      <td>130.502991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>132.630005</td>\n",
       "      <td>130.229996</td>\n",
       "      <td>132.429993</td>\n",
       "      <td>132.050003</td>\n",
       "      <td>105158200.0</td>\n",
       "      <td>131.629379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>130.169998</td>\n",
       "      <td>128.500000</td>\n",
       "      <td>129.190002</td>\n",
       "      <td>128.979996</td>\n",
       "      <td>100384500.0</td>\n",
       "      <td>128.569168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>132.410004</td>\n",
       "      <td>129.210007</td>\n",
       "      <td>130.300003</td>\n",
       "      <td>132.300003</td>\n",
       "      <td>79663300.0</td>\n",
       "      <td>132.300003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>134.080002</td>\n",
       "      <td>131.619995</td>\n",
       "      <td>132.130005</td>\n",
       "      <td>133.979996</td>\n",
       "      <td>74783600.0</td>\n",
       "      <td>133.979996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>134.320007</td>\n",
       "      <td>133.229996</td>\n",
       "      <td>133.770004</td>\n",
       "      <td>133.699997</td>\n",
       "      <td>60214200.0</td>\n",
       "      <td>133.699997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>134.639999</td>\n",
       "      <td>132.929993</td>\n",
       "      <td>134.449997</td>\n",
       "      <td>133.410004</td>\n",
       "      <td>68711000.0</td>\n",
       "      <td>133.410004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>133.889999</td>\n",
       "      <td>132.809998</td>\n",
       "      <td>133.460007</td>\n",
       "      <td>133.110001</td>\n",
       "      <td>70730700.0</td>\n",
       "      <td>133.110001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            High         Low        Open       Close       Volume   Adj Close\n",
       "2266  131.740005  128.429993  128.889999  131.009995   97664900.0  130.592697\n",
       "2267  131.050003  126.379997  127.720001  126.599998  155088000.0  126.196747\n",
       "2268  131.630005  127.860001  128.360001  130.919998  109578200.0  130.502991\n",
       "2269  132.630005  130.229996  132.429993  132.050003  105158200.0  131.629379\n",
       "2270  130.169998  128.500000  129.190002  128.979996  100384500.0  128.569168\n",
       "...          ...         ...         ...         ...          ...         ...\n",
       "2381  132.410004  129.210007  130.300003  132.300003   79663300.0  132.300003\n",
       "2382  134.080002  131.619995  132.130005  133.979996   74783600.0  133.979996\n",
       "2383  134.320007  133.229996  133.770004  133.699997   60214200.0  133.699997\n",
       "2384  134.639999  132.929993  134.449997  133.410004   68711000.0  133.410004\n",
       "2385  133.889999  132.809998  133.460007  133.110001   70730700.0  133.110001\n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[int(lstm_training_lata_len-1):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b7a26ed",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[117.        , 114.91999817, 115.27999878, 116.97000122],\n",
       "       [125.18000031, 119.27999878, 120.05999756, 124.40000153],\n",
       "       [125.38999939, 119.65000153, 125.26999664, 121.09999847],\n",
       "       [123.02999878, 119.62000275, 121.        , 121.19000244],\n",
       "       [121.19999695, 118.15000153, 118.72000122, 120.70999908],\n",
       "       [121.55000305, 118.80999756, 121.27999878, 119.01999664],\n",
       "       [120.41999817, 115.66000366, 119.95999908, 115.98000336],\n",
       "       [118.98000336, 115.62999725, 116.19999695, 117.51000214],\n",
       "       [118.70999908, 116.44999695, 116.66999817, 116.87000275],\n",
       "       [118.04000092, 114.58999634, 117.44999695, 115.75      ],\n",
       "       [116.55000305, 114.27999878, 116.38999939, 115.04000092],\n",
       "       [116.55000305, 112.87999725, 114.01000214, 115.05000305],\n",
       "       [117.27999878, 114.54000092, 115.48999786, 116.59999847],\n",
       "       [115.43000031, 111.09999847, 115.05000305, 111.19999695],\n",
       "       [116.93000031, 112.19999695, 112.37000275, 115.31999969],\n",
       "       [111.98999786, 107.72000122, 111.05999756, 108.86000061],\n",
       "       [110.68000031, 107.31999969, 109.11000061, 108.76999664],\n",
       "       [111.48999786, 108.73000336, 109.66000366, 110.44000244],\n",
       "       [115.58999634, 112.34999847, 114.13999939, 114.94999695],\n",
       "       [119.62000275, 116.87000275, 117.94999695, 119.02999878],\n",
       "       [119.19999695, 116.12999725, 118.31999969, 118.69000244],\n",
       "       [121.98999786, 116.05000305, 120.5       , 116.31999969],\n",
       "       [117.58999634, 114.12999725, 115.55000305, 115.97000122],\n",
       "       [119.62999725, 116.44000244, 117.19000244, 119.48999786],\n",
       "       [120.52999878, 118.56999969, 119.62000275, 119.20999908],\n",
       "       [119.66999817, 117.87000275, 119.44000244, 119.26000214],\n",
       "       [120.98999786, 118.15000153, 118.91999817, 120.30000305],\n",
       "       [120.66999817, 118.95999908, 119.55000305, 119.38999939],\n",
       "       [119.81999969, 118.        , 118.61000061, 118.02999878],\n",
       "       [119.05999756, 116.80999756, 117.58999634, 118.63999939],\n",
       "       [118.76999664, 117.29000092, 118.63999939, 117.33999634],\n",
       "       [117.62000275, 113.75      , 117.18000031, 113.84999847],\n",
       "       [115.84999847, 112.58999634, 113.91000366, 115.16999817],\n",
       "       [116.75      , 115.16999817, 115.55000305, 116.02999878],\n",
       "       [117.48999786, 116.22000122, 116.56999969, 116.58999634],\n",
       "       [120.97000122, 116.80999756, 116.97000122, 119.05000305],\n",
       "       [123.47000122, 120.01000214, 121.01000214, 122.72000122],\n",
       "       [123.37000275, 120.88999939, 122.01999664, 123.08000183],\n",
       "       [123.77999878, 122.20999908, 123.51999664, 122.94000244],\n",
       "       [122.86000061, 121.51999664, 122.59999847, 122.25      ],\n",
       "       [124.56999969, 122.25      , 122.30999756, 123.75      ],\n",
       "       [124.98000336, 123.08999634, 124.37000275, 124.37999725],\n",
       "       [125.94999695, 121.        , 124.52999878, 121.77999878],\n",
       "       [123.87000275, 120.15000153, 120.5       , 123.23999786],\n",
       "       [122.76000214, 120.55000305, 122.43000031, 122.41000366],\n",
       "       [123.34999847, 121.54000092, 122.59999847, 121.77999878],\n",
       "       [127.90000153, 124.12999725, 124.33999634, 127.87999725],\n",
       "       [128.36999512, 126.55999756, 127.41000366, 127.80999756],\n",
       "       [129.58000183, 128.03999329, 128.8999939 , 128.69999695],\n",
       "       [129.1000061 , 126.12000275, 128.96000671, 126.66000366],\n",
       "       [128.30999756, 123.44999695, 125.01999664, 128.22999573],\n",
       "       [134.41000366, 129.6499939 , 131.61000061, 131.88000488],\n",
       "       [132.42999268, 130.77999878, 132.16000366, 130.96000671],\n",
       "       [133.46000671, 131.1000061 , 131.32000732, 131.97000122],\n",
       "       [137.33999634, 133.50999451, 133.99000549, 136.69000244],\n",
       "       [138.78999329, 134.33999634, 138.05000305, 134.86999512],\n",
       "       [135.99000549, 133.3999939 , 135.58000183, 133.72000122],\n",
       "       [134.74000549, 131.72000122, 134.08000183, 132.69000244],\n",
       "       [133.61000061, 126.76000214, 133.52000427, 129.41000366],\n",
       "       [131.74000549, 128.42999268, 128.88999939, 131.00999451],\n",
       "       [131.05000305, 126.37999725, 127.72000122, 126.59999847],\n",
       "       [131.63000488, 127.86000061, 128.36000061, 130.91999817],\n",
       "       [132.63000488, 130.22999573, 132.42999268, 132.05000305],\n",
       "       [130.16999817, 128.5       , 129.19000244, 128.97999573],\n",
       "       [129.69000244, 126.86000061, 128.5       , 128.80000305],\n",
       "       [131.44999695, 128.49000549, 128.75999451, 130.88999939],\n",
       "       [131.        , 128.75999451, 130.80000305, 128.91000366],\n",
       "       [130.22000122, 127.        , 128.77999878, 127.13999939],\n",
       "       [128.71000671, 126.94000244, 127.77999878, 127.83000183],\n",
       "       [132.49000549, 128.55000305, 128.66000366, 132.02999878],\n",
       "       [139.66999817, 133.58999634, 133.80000305, 136.86999512],\n",
       "       [139.8500061 , 135.02000427, 136.27999878, 139.07000732],\n",
       "       [145.08999634, 136.53999329, 143.07000732, 142.91999817],\n",
       "       [144.30000305, 141.36999512, 143.6000061 , 143.16000366],\n",
       "       [144.30000305, 140.41000366, 143.42999268, 142.05999756],\n",
       "       [141.99000549, 136.69999695, 139.52000427, 137.08999634],\n",
       "       [136.74000549, 130.21000671, 135.83000183, 131.96000671],\n",
       "       [135.38000488, 130.92999268, 133.75      , 134.13999939],\n",
       "       [136.30999756, 134.61000061, 135.72999573, 134.99000549],\n",
       "       [135.77000427, 133.61000061, 135.75999451, 133.94000244],\n",
       "       [137.3999939 , 134.58999634, 136.30000305, 137.38999939],\n",
       "       [137.41999817, 135.86000061, 137.3500061 , 136.75999451],\n",
       "       [136.96000671, 134.91999817, 136.02999878, 136.91000366],\n",
       "       [137.88000488, 135.8500061 , 136.61999512, 136.00999451],\n",
       "       [136.99000549, 134.3999939 , 136.47999573, 135.38999939],\n",
       "       [136.38999939, 133.77000427, 135.8999939 , 135.13000488],\n",
       "       [135.52999878, 133.69000244, 134.3500061 , 135.36999512],\n",
       "       [136.00999451, 132.78999329, 135.49000549, 133.19000244],\n",
       "       [132.22000122, 129.47000122, 131.25      , 130.83999634],\n",
       "       [130.        , 127.41000366, 129.19999695, 129.71000671],\n",
       "       [130.71000671, 128.80000305, 130.24000549, 129.86999512],\n",
       "       [129.72000122, 125.59999847, 128.00999451, 126.        ],\n",
       "       [126.70999908, 118.38999939, 123.76000214, 125.86000061],\n",
       "       [125.55999756, 122.23000336, 124.94000244, 125.34999847],\n",
       "       [126.45999908, 120.54000092, 124.68000031, 120.98999786],\n",
       "       [124.84999847, 121.19999695, 122.58999634, 121.26000214],\n",
       "       [127.93000031, 122.79000092, 123.75      , 127.79000092],\n",
       "       [128.72000122, 125.01000214, 128.41000366, 125.12000275],\n",
       "       [125.70999908, 121.83999634, 124.80999756, 122.05999756],\n",
       "       [123.59999847, 118.62000275, 121.75      , 120.12999725],\n",
       "       [121.94000244, 117.56999969, 120.98000336, 121.41999817],\n",
       "       [121.        , 116.20999908, 120.93000031, 116.36000061],\n",
       "       [122.05999756, 118.79000092, 119.02999878, 121.08999634],\n",
       "       [122.16999817, 119.44999695, 121.69000244, 119.98000336],\n",
       "       [123.20999908, 121.26000214, 122.54000092, 121.95999908],\n",
       "       [121.16999817, 119.16000366, 120.40000153, 121.02999878],\n",
       "       [124.        , 120.41999817, 121.41000366, 123.98999786],\n",
       "       [127.22000122, 124.72000122, 125.69999695, 125.56999969],\n",
       "       [125.86000061, 122.33999634, 124.05000305, 124.76000214],\n",
       "       [123.18000031, 120.31999969, 122.87999725, 120.52999878],\n",
       "       [121.43000031, 119.68000031, 119.90000153, 119.98999786],\n",
       "       [123.87000275, 120.26000214, 120.33000183, 123.38999939],\n",
       "       [124.23999786, 122.13999939, 123.33000183, 122.54000092],\n",
       "       [122.90000153, 120.06999969, 122.81999969, 120.08999634],\n",
       "       [121.66000366, 119.        , 119.54000092, 120.58999634],\n",
       "       [121.48000336, 118.91999817, 120.34999847, 121.20999908],\n",
       "       [122.58000183, 120.73000336, 121.65000153, 121.38999939],\n",
       "       [120.40000153, 118.86000061, 120.11000061, 119.90000153],\n",
       "       [123.51999664, 121.15000153, 121.65000153, 122.15000153],\n",
       "       [124.18000031, 122.48999786, 123.66000366, 123.        ],\n",
       "       [126.16000366, 123.06999969, 123.87000275, 125.90000153],\n",
       "       [127.12999725, 125.65000153, 126.5       , 126.20999908],\n",
       "       [127.91999817, 125.13999939, 125.83000183, 127.90000153],\n",
       "       [130.38999939, 128.52000427, 128.94999695, 130.36000061],\n",
       "       [133.03999329, 129.47000122, 129.80000305, 133.        ],\n",
       "       [132.8500061 , 130.63000488, 132.52000427, 131.24000549],\n",
       "       [134.66000366, 131.92999268, 132.44000244, 134.42999268],\n",
       "       [135.        , 131.66000366, 134.94000244, 132.02999878],\n",
       "       [135.        , 133.63999939, 133.82000732, 134.5       ],\n",
       "       [134.66999817, 133.27999878, 134.30000305, 134.16000366],\n",
       "       [135.47000122, 133.33999634, 133.50999451, 134.83999634],\n",
       "       [135.52999878, 131.80999756, 135.02000427, 133.11000061],\n",
       "       [133.75      , 131.30000305, 132.36000061, 133.5       ],\n",
       "       [134.1499939 , 131.41000366, 133.03999329, 131.94000244],\n",
       "       [135.11999512, 132.16000366, 132.16000366, 134.32000732],\n",
       "       [135.05999756, 133.55999756, 134.83000183, 134.72000122],\n",
       "       [135.41000366, 134.11000061, 135.00999451, 134.38999939],\n",
       "       [135.02000427, 133.08000183, 134.30999756, 133.58000183],\n",
       "       [137.07000732, 132.44999695, 136.47000122, 133.47999573],\n",
       "       [133.55999756, 131.07000732, 131.77999878, 131.46000671],\n",
       "       [134.07000732, 131.83000183, 132.03999329, 132.53999329],\n",
       "       [131.49000549, 126.69999695, 131.19000244, 127.84999847],\n",
       "       [130.44999695, 127.97000122, 129.19999695, 128.1000061 ],\n",
       "       [129.75      , 127.12999725, 127.88999939, 129.74000549],\n",
       "       [131.25999451, 129.47999573, 130.8500061 , 130.21000671],\n",
       "       [129.53999329, 126.80999756, 129.41000366, 126.84999847],\n",
       "       [126.26999664, 122.76999664, 123.5       , 125.91000366],\n",
       "       [124.63999939, 122.25      , 123.40000153, 122.76999664],\n",
       "       [126.15000153, 124.26000214, 124.58000183, 124.97000122],\n",
       "       [127.88999939, 125.84999847, 126.25      , 127.44999695],\n",
       "       [126.93000031, 125.16999817, 126.81999969, 126.26999664],\n",
       "       [126.98999786, 124.77999878, 126.55999756, 124.84999847],\n",
       "       [124.91999817, 122.86000061, 123.16000366, 124.69000244],\n",
       "       [127.72000122, 125.09999847, 125.23000336, 127.30999756],\n",
       "       [128.        , 125.20999908, 127.81999969, 125.43000031],\n",
       "       [127.94000244, 125.94000244, 126.01000214, 127.09999847],\n",
       "       [128.32000732, 126.31999969, 127.81999969, 126.90000153],\n",
       "       [127.38999939, 126.41999817, 126.95999908, 126.84999847],\n",
       "       [127.63999939, 125.08000183, 126.44000244, 125.27999878],\n",
       "       [125.80000305, 124.55000305, 125.56999969, 124.61000061],\n",
       "       [125.34999847, 123.94000244, 125.08000183, 124.27999878],\n",
       "       [125.23999786, 124.05000305, 124.27999878, 125.05999756],\n",
       "       [124.84999847, 123.12999725, 124.68000031, 123.54000092],\n",
       "       [126.16000366, 123.84999847, 124.06999969, 125.88999939],\n",
       "       [126.31999969, 124.83000183, 126.16999817, 125.90000153],\n",
       "       [128.46000671, 126.20999908, 126.59999847, 126.73999786],\n",
       "       [127.75      , 126.51999664, 127.20999908, 127.12999725],\n",
       "       [128.19000244, 125.94000244, 127.01999664, 126.11000061],\n",
       "       [127.44000244, 126.09999847, 126.52999878, 127.34999847],\n",
       "       [130.53999329, 127.06999969, 127.81999969, 130.47999573],\n",
       "       [130.6000061 , 129.38999939, 129.94000244, 129.63999939],\n",
       "       [130.88999939, 128.46000671, 130.36999512, 130.1499939 ],\n",
       "       [132.55000305, 129.6499939 , 129.80000305, 131.78999329],\n",
       "       [131.50999451, 130.24000549, 130.71000671, 130.46000671],\n",
       "       [132.41000366, 129.21000671, 130.30000305, 132.30000305],\n",
       "       [134.08000183, 131.61999512, 132.13000488, 133.97999573],\n",
       "       [134.32000732, 133.22999573, 133.77000427, 133.69999695],\n",
       "       [134.63999939, 132.92999268, 134.44999695, 133.41000366],\n",
       "       [133.88999939, 132.80999756, 133.46000671, 133.11000061]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = hstack((lstm_test_in_seq1,lstm_test_in_seq2,lstm_test_in_seq3,lstm_test_out_seq))\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d9c944",
   "metadata": {},
   "source": [
    "1.. 60 => 61\n",
    "2.. 61 => 62 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909982c7",
   "metadata": {},
   "source": [
    "1.. 5  => 6\n",
    "2.. 6  => 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b1cecc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def veriyi_bol(veri, n_steps):\n",
    "    X, y = list() , list()\n",
    "    for i in range(len(veri)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(veri):\n",
    "            break\n",
    "        seq_x, seq_y = veri[i: end_ix, : -1], veri[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a66eb261",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d62b031f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 14.7321434 ,  14.6071434 ,  14.62142944],\n",
       "        [ 14.81000042,  14.61714268,  14.6428566 ],\n",
       "        [ 14.94821358,  14.73821354,  14.81964302],\n",
       "        [ 15.09821415,  14.97214317,  14.991786  ],\n",
       "        [ 15.27678585,  15.04821396,  15.19642925]],\n",
       "\n",
       "       [[ 14.81000042,  14.61714268,  14.6428566 ],\n",
       "        [ 14.94821358,  14.73821354,  14.81964302],\n",
       "        [ 15.09821415,  14.97214317,  14.991786  ],\n",
       "        [ 15.27678585,  15.04821396,  15.19642925],\n",
       "        [ 15.21428585,  15.05357075,  15.21107101]],\n",
       "\n",
       "       [[ 14.94821358,  14.73821354,  14.81964302],\n",
       "        [ 15.09821415,  14.97214317,  14.991786  ],\n",
       "        [ 15.27678585,  15.04821396,  15.19642925],\n",
       "        [ 15.21428585,  15.05357075,  15.21107101],\n",
       "        [ 15.10178566,  14.97535706,  15.09571362]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[133.46000671, 131.1000061 , 131.32000732],\n",
       "        [137.33999634, 133.50999451, 133.99000549],\n",
       "        [138.78999329, 134.33999634, 138.05000305],\n",
       "        [135.99000549, 133.3999939 , 135.58000183],\n",
       "        [134.74000549, 131.72000122, 134.08000183]],\n",
       "\n",
       "       [[137.33999634, 133.50999451, 133.99000549],\n",
       "        [138.78999329, 134.33999634, 138.05000305],\n",
       "        [135.99000549, 133.3999939 , 135.58000183],\n",
       "        [134.74000549, 131.72000122, 134.08000183],\n",
       "        [133.61000061, 126.76000214, 133.52000427]],\n",
       "\n",
       "       [[138.78999329, 134.33999634, 138.05000305],\n",
       "        [135.99000549, 133.3999939 , 135.58000183],\n",
       "        [134.74000549, 131.72000122, 134.08000183],\n",
       "        [133.61000061, 126.76000214, 133.52000427],\n",
       "        [131.74000549, 128.42999268, 128.88999939]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = veriyi_bol(train_dataset, n_steps)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "850fceaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15.0617857 ,  15.11571407,  15.09107113, ..., 132.69000244,\n",
       "       129.41000366, 131.00999451])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00e81da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[117.        , 114.91999817, 115.27999878],\n",
       "        [125.18000031, 119.27999878, 120.05999756],\n",
       "        [125.38999939, 119.65000153, 125.26999664],\n",
       "        [123.02999878, 119.62000275, 121.        ],\n",
       "        [121.19999695, 118.15000153, 118.72000122]],\n",
       "\n",
       "       [[125.18000031, 119.27999878, 120.05999756],\n",
       "        [125.38999939, 119.65000153, 125.26999664],\n",
       "        [123.02999878, 119.62000275, 121.        ],\n",
       "        [121.19999695, 118.15000153, 118.72000122],\n",
       "        [121.55000305, 118.80999756, 121.27999878]],\n",
       "\n",
       "       [[125.38999939, 119.65000153, 125.26999664],\n",
       "        [123.02999878, 119.62000275, 121.        ],\n",
       "        [121.19999695, 118.15000153, 118.72000122],\n",
       "        [121.55000305, 118.80999756, 121.27999878],\n",
       "        [120.41999817, 115.66000366, 119.95999908]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[132.55000305, 129.6499939 , 129.80000305],\n",
       "        [131.50999451, 130.24000549, 130.71000671],\n",
       "        [132.41000366, 129.21000671, 130.30000305],\n",
       "        [134.08000183, 131.61999512, 132.13000488],\n",
       "        [134.32000732, 133.22999573, 133.77000427]],\n",
       "\n",
       "       [[131.50999451, 130.24000549, 130.71000671],\n",
       "        [132.41000366, 129.21000671, 130.30000305],\n",
       "        [134.08000183, 131.61999512, 132.13000488],\n",
       "        [134.32000732, 133.22999573, 133.77000427],\n",
       "        [134.63999939, 132.92999268, 134.44999695]],\n",
       "\n",
       "       [[132.41000366, 129.21000671, 130.30000305],\n",
       "        [134.08000183, 131.61999512, 132.13000488],\n",
       "        [134.32000732, 133.22999573, 133.77000427],\n",
       "        [134.63999939, 132.92999268, 134.44999695],\n",
       "        [133.88999939, 132.80999756, 133.46000671]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = veriyi_bol(test_dataset, n_steps)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e0b0c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM ve model importları\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c2274f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2263, 5, 3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "58a1bb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = X_train.shape[2]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4cc34352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 5, 256)            266240    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 463,489\n",
      "Trainable params: 463,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model oluşturma\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, return_sequences = True, activation = \"relu\", input_shape=(n_steps, n_features) ))\n",
    "model.add(LSTM(128, return_sequences = False))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "51048b69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 176.9249 - val_loss: 3981.5920\n",
      "Epoch 2/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 165.8388 - val_loss: 3798.8250\n",
      "Epoch 3/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 155.5003 - val_loss: 3625.2861\n",
      "Epoch 4/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 146.0587 - val_loss: 3460.5156\n",
      "Epoch 5/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 137.7038 - val_loss: 3305.1021\n",
      "Epoch 6/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 129.3590 - val_loss: 3147.4231\n",
      "Epoch 7/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 121.2073 - val_loss: 3003.6443\n",
      "Epoch 8/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 114.5082 - val_loss: 2873.4932\n",
      "Epoch 9/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 107.4794 - val_loss: 2740.7810\n",
      "Epoch 10/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 101.2387 - val_loss: 2616.2021\n",
      "Epoch 11/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 95.3139 - val_loss: 2491.6990\n",
      "Epoch 12/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 89.1593 - val_loss: 2359.1721\n",
      "Epoch 13/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 83.6819 - val_loss: 2255.2773\n",
      "Epoch 14/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 79.3585 - val_loss: 2147.3521\n",
      "Epoch 15/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 74.6703 - val_loss: 2049.3022\n",
      "Epoch 16/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 71.2975 - val_loss: 1946.2396\n",
      "Epoch 17/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 66.0745 - val_loss: 1855.4204\n",
      "Epoch 18/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 62.0597 - val_loss: 1768.3774\n",
      "Epoch 19/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 58.2833 - val_loss: 1681.8750\n",
      "Epoch 20/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 54.7959 - val_loss: 1595.1975\n",
      "Epoch 21/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 51.3842 - val_loss: 1525.5763\n",
      "Epoch 22/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 49.0393 - val_loss: 1449.6371\n",
      "Epoch 23/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 45.5746 - val_loss: 1374.2698\n",
      "Epoch 24/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 42.9199 - val_loss: 1303.8871\n",
      "Epoch 25/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 39.9659 - val_loss: 1243.7762\n",
      "Epoch 26/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 37.8349 - val_loss: 1180.0652\n",
      "Epoch 27/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 35.4461 - val_loss: 1118.9822\n",
      "Epoch 28/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 33.2107 - val_loss: 1065.6893\n",
      "Epoch 29/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 30.9232 - val_loss: 1006.2173\n",
      "Epoch 30/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 28.9406 - val_loss: 946.6061\n",
      "Epoch 31/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 26.7593 - val_loss: 883.1744\n",
      "Epoch 32/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 24.8940 - val_loss: 823.8773\n",
      "Epoch 33/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 22.7045 - val_loss: 772.4159\n",
      "Epoch 34/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 20.6723 - val_loss: 717.7657\n",
      "Epoch 35/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 19.2926 - val_loss: 675.2281\n",
      "Epoch 36/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 17.6308 - val_loss: 635.5767\n",
      "Epoch 37/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 17.1973 - val_loss: 599.3194\n",
      "Epoch 38/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 15.2018 - val_loss: 565.0749\n",
      "Epoch 39/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 14.5934 - val_loss: 531.5383 13.\n",
      "Epoch 40/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 13.0601 - val_loss: 500.7180\n",
      "Epoch 41/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 12.2420 - val_loss: 472.3088\n",
      "Epoch 42/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 11.8240 - val_loss: 446.9280\n",
      "Epoch 43/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 11.7302 - val_loss: 422.3236\n",
      "Epoch 44/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 10.6477 - val_loss: 400.6508\n",
      "Epoch 45/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 10.2138 - val_loss: 352.4605\n",
      "Epoch 46/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 8.6350 - val_loss: 318.1403\n",
      "Epoch 47/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 8.9221 - val_loss: 296.2720\n",
      "Epoch 48/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 6.6234 - val_loss: 271.9981\n",
      "Epoch 49/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 5.9290 - val_loss: 253.1777\n",
      "Epoch 50/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 5.5116 - val_loss: 236.5883\n",
      "Epoch 51/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 4.9960 - val_loss: 222.2432\n",
      "Epoch 52/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 4.8003 - val_loss: 208.5650\n",
      "Epoch 53/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 6.1027 - val_loss: 200.8359\n",
      "Epoch 54/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 5.1613 - val_loss: 186.1054\n",
      "Epoch 55/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.2525 - val_loss: 170.4658\n",
      "Epoch 56/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 4.1252 - val_loss: 158.1262\n",
      "Epoch 57/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 3.6235 - val_loss: 149.1579\n",
      "Epoch 58/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 3.3281 - val_loss: 141.1216\n",
      "Epoch 59/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 3.3793 - val_loss: 133.5433\n",
      "Epoch 60/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 3.4468 - val_loss: 134.4752\n",
      "Epoch 61/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 3.7200 - val_loss: 121.0357\n",
      "Epoch 62/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 3.4679 - val_loss: 125.3937\n",
      "Epoch 63/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 2.8827 - val_loss: 110.8900\n",
      "Epoch 64/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 3.2821 - val_loss: 106.4112\n",
      "Epoch 65/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 3.1638 - val_loss: 121.0717\n",
      "Epoch 66/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 3.2037 - val_loss: 96.4356\n",
      "Epoch 67/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 3.4202 - val_loss: 92.6820\n",
      "Epoch 68/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 2.5455 - val_loss: 85.2999\n",
      "Epoch 69/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 2.9179 - val_loss: 81.7042: 0s - loss: \n",
      "Epoch 70/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 2.2074 - val_loss: 77.5471\n",
      "Epoch 71/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 2.4070 - val_loss: 73.7919\n",
      "Epoch 72/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 2.2171 - val_loss: 72.7787\n",
      "Epoch 73/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 2.0418 - val_loss: 66.8920\n",
      "Epoch 74/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 1.9235 - val_loss: 63.1054\n",
      "Epoch 75/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 1.9645 - val_loss: 63.4410\n",
      "Epoch 76/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 2.8026 - val_loss: 75.1498\n",
      "Epoch 77/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 2.1893 - val_loss: 56.4524\n",
      "Epoch 78/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 2.4785 - val_loss: 76.2715\n",
      "Epoch 79/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 1.8693 - val_loss: 64.7337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 1.8798 - val_loss: 60.9175\n",
      "Epoch 81/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 1.9014 - val_loss: 60.2300\n",
      "Epoch 82/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 1.8684 - val_loss: 56.4894\n",
      "Epoch 83/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 1.7527 - val_loss: 53.9837\n",
      "Epoch 84/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 1.7945 - val_loss: 52.0052\n",
      "Epoch 85/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 2.9756 - val_loss: 50.5920\n",
      "Epoch 86/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 1.8988 - val_loss: 46.1458\n",
      "Epoch 87/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 1.5053 - val_loss: 42.8241\n",
      "Epoch 88/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 1.3853 - val_loss: 50.8477\n",
      "Epoch 89/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 1.3647 - val_loss: 39.2546\n",
      "Epoch 90/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 1.5684 - val_loss: 48.0947\n",
      "Epoch 91/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 1.1422 - val_loss: 37.1649\n",
      "Epoch 92/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 1.4734 - val_loss: 44.1665\n",
      "Epoch 93/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 1.7345 - val_loss: 36.7923\n",
      "Epoch 94/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 1.1713 - val_loss: 30.6993\n",
      "Epoch 95/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 1.3651 - val_loss: 30.0235\n",
      "Epoch 96/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 1.1577 - val_loss: 25.4955\n",
      "Epoch 97/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.9312 - val_loss: 23.9573\n",
      "Epoch 98/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.9199 - val_loss: 26.8399\n",
      "Epoch 99/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 1.1010 - val_loss: 23.5446\n",
      "Epoch 100/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 1.0763 - val_loss: 23.5668\n",
      "Epoch 101/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.9102 - val_loss: 21.0311\n",
      "Epoch 102/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 1.2279 - val_loss: 22.8422\n",
      "Epoch 103/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.9412 - val_loss: 20.9021\n",
      "Epoch 104/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.7482 - val_loss: 17.9798\n",
      "Epoch 105/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.7860 - val_loss: 20.1745\n",
      "Epoch 106/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.6516 - val_loss: 16.6357\n",
      "Epoch 107/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.6471 - val_loss: 22.8701\n",
      "Epoch 108/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.9719 - val_loss: 16.9718\n",
      "Epoch 109/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 1.1998 - val_loss: 19.4011\n",
      "Epoch 110/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.7026 - val_loss: 14.7166\n",
      "Epoch 111/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.9752 - val_loss: 15.8150\n",
      "Epoch 112/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.6338 - val_loss: 13.7814\n",
      "Epoch 113/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.6828 - val_loss: 13.1146\n",
      "Epoch 114/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.6336 - val_loss: 13.7538\n",
      "Epoch 115/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.6411 - val_loss: 12.5322\n",
      "Epoch 116/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.4829 - val_loss: 11.8804\n",
      "Epoch 117/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.5891 - val_loss: 12.3907\n",
      "Epoch 118/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.5822 - val_loss: 11.7151\n",
      "Epoch 119/500\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 1.0047 - val_loss: 11.8412\n",
      "Epoch 120/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 1.2459 - val_loss: 13.8942\n",
      "Epoch 121/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.7615 - val_loss: 12.9987\n",
      "Epoch 122/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.6205 - val_loss: 11.3955\n",
      "Epoch 123/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.4828 - val_loss: 11.2406\n",
      "Epoch 124/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.5029 - val_loss: 10.0377\n",
      "Epoch 125/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.5457 - val_loss: 10.1703\n",
      "Epoch 126/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.4373 - val_loss: 9.5701\n",
      "Epoch 127/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.4859 - val_loss: 11.0432\n",
      "Epoch 128/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.7055 - val_loss: 14.5028\n",
      "Epoch 129/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.7704 - val_loss: 11.3141\n",
      "Epoch 130/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.5041 - val_loss: 8.5913\n",
      "Epoch 131/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.4266 - val_loss: 8.4667\n",
      "Epoch 132/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3279 - val_loss: 8.6399\n",
      "Epoch 133/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3583 - val_loss: 9.7099\n",
      "Epoch 134/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3599 - val_loss: 9.7020\n",
      "Epoch 135/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.3524 - val_loss: 7.9439\n",
      "Epoch 136/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3025 - val_loss: 8.8299\n",
      "Epoch 137/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.5258 - val_loss: 8.1182\n",
      "Epoch 138/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.4707 - val_loss: 9.7206\n",
      "Epoch 139/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3895 - val_loss: 7.4629\n",
      "Epoch 140/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3719 - val_loss: 6.6382\n",
      "Epoch 141/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3946 - val_loss: 7.2940\n",
      "Epoch 142/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.3422 - val_loss: 6.2048\n",
      "Epoch 143/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.4846 - val_loss: 9.1972\n",
      "Epoch 144/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.3359 - val_loss: 15.7446\n",
      "Epoch 145/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.5292 - val_loss: 23.9410\n",
      "Epoch 146/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.5076 - val_loss: 7.2311\n",
      "Epoch 147/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3130 - val_loss: 6.3616\n",
      "Epoch 148/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.4801 - val_loss: 7.6034\n",
      "Epoch 149/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.4026 - val_loss: 9.2877\n",
      "Epoch 150/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2843 - val_loss: 7.3670\n",
      "Epoch 151/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.3513 - val_loss: 7.3990\n",
      "Epoch 152/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.3037 - val_loss: 5.4923\n",
      "Epoch 153/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3153 - val_loss: 5.9350\n",
      "Epoch 154/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3469 - val_loss: 5.1263\n",
      "Epoch 155/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2838 - val_loss: 4.8774\n",
      "Epoch 156/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3428 - val_loss: 6.1754\n",
      "Epoch 157/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2415 - val_loss: 5.6614\n",
      "Epoch 158/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.3407 - val_loss: 9.6751\n",
      "Epoch 159/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.4167 - val_loss: 7.1505\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 22ms/step - loss: 0.3301 - val_loss: 4.8353\n",
      "Epoch 161/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.3394 - val_loss: 6.9641\n",
      "Epoch 162/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2373 - val_loss: 7.3407\n",
      "Epoch 163/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.2699 - val_loss: 4.4901\n",
      "Epoch 164/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2743 - val_loss: 11.4952\n",
      "Epoch 165/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.8470 - val_loss: 6.4904\n",
      "Epoch 166/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.3570 - val_loss: 5.3878\n",
      "Epoch 167/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2096 - val_loss: 7.7728\n",
      "Epoch 168/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2713 - val_loss: 9.1852\n",
      "Epoch 169/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.5434 - val_loss: 5.1611\n",
      "Epoch 170/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.5283 - val_loss: 6.1436\n",
      "Epoch 171/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.4485 - val_loss: 4.9511\n",
      "Epoch 172/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2622 - val_loss: 5.3043\n",
      "Epoch 173/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2711 - val_loss: 4.0745\n",
      "Epoch 174/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2309 - val_loss: 4.0639\n",
      "Epoch 175/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2208 - val_loss: 5.1817\n",
      "Epoch 176/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.3173 - val_loss: 4.7237\n",
      "Epoch 177/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2630 - val_loss: 4.2114\n",
      "Epoch 178/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2073 - val_loss: 7.9663\n",
      "Epoch 179/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.3347 - val_loss: 6.0291\n",
      "Epoch 180/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.3147 - val_loss: 4.3708\n",
      "Epoch 181/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.3941 - val_loss: 5.1938\n",
      "Epoch 182/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.2475 - val_loss: 3.6731\n",
      "Epoch 183/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.4003 - val_loss: 3.5530\n",
      "Epoch 184/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3156 - val_loss: 3.3906\n",
      "Epoch 185/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2084 - val_loss: 4.4801\n",
      "Epoch 186/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2444 - val_loss: 3.7142\n",
      "Epoch 187/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2143 - val_loss: 3.1847\n",
      "Epoch 188/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2108 - val_loss: 4.9088\n",
      "Epoch 189/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2171 - val_loss: 10.5822\n",
      "Epoch 190/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.3546 - val_loss: 3.6864\n",
      "Epoch 191/500\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 0.2667 - val_loss: 3.2317\n",
      "Epoch 192/500\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.2498 - val_loss: 3.2520\n",
      "Epoch 193/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.3175 - val_loss: 4.0962\n",
      "Epoch 194/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.4433 - val_loss: 5.9789\n",
      "Epoch 195/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2770 - val_loss: 3.2418\n",
      "Epoch 196/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.2526 - val_loss: 4.1130\n",
      "Epoch 197/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2136 - val_loss: 3.2043\n",
      "Epoch 198/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1925 - val_loss: 3.4060\n",
      "Epoch 199/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2361 - val_loss: 4.1182\n",
      "Epoch 200/500\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.2273 - val_loss: 3.1321\n",
      "Epoch 201/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.1679 - val_loss: 7.1104\n",
      "Epoch 202/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.4422 - val_loss: 4.1645\n",
      "Epoch 203/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2511 - val_loss: 3.3726\n",
      "Epoch 204/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2797 - val_loss: 2.7555\n",
      "Epoch 205/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.2551 - val_loss: 2.8787\n",
      "Epoch 206/500\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.4150 - val_loss: 4.3186\n",
      "Epoch 207/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3084 - val_loss: 5.8433\n",
      "Epoch 208/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2311 - val_loss: 5.8021\n",
      "Epoch 209/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3765 - val_loss: 3.9380\n",
      "Epoch 210/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.5069 - val_loss: 5.0794\n",
      "Epoch 211/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.5673 - val_loss: 5.7605\n",
      "Epoch 212/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3264 - val_loss: 4.9021\n",
      "Epoch 213/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2264 - val_loss: 5.5105\n",
      "Epoch 214/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.4214 - val_loss: 4.4764\n",
      "Epoch 215/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.3334 - val_loss: 4.1273\n",
      "Epoch 216/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2080 - val_loss: 2.8320\n",
      "Epoch 217/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2134 - val_loss: 3.7064\n",
      "Epoch 218/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2538 - val_loss: 3.5487\n",
      "Epoch 219/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2417 - val_loss: 8.0548\n",
      "Epoch 220/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3244 - val_loss: 2.9285\n",
      "Epoch 221/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2240 - val_loss: 5.3422\n",
      "Epoch 222/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2787 - val_loss: 2.9827\n",
      "Epoch 223/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1836 - val_loss: 3.0596\n",
      "Epoch 224/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2193 - val_loss: 3.1600\n",
      "Epoch 225/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2474 - val_loss: 5.3486\n",
      "Epoch 226/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2959 - val_loss: 3.8112\n",
      "Epoch 227/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3283 - val_loss: 2.6921\n",
      "Epoch 228/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2370 - val_loss: 3.3901\n",
      "Epoch 229/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2397 - val_loss: 2.4548\n",
      "Epoch 230/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2235 - val_loss: 5.0992\n",
      "Epoch 231/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1933 - val_loss: 4.1431\n",
      "Epoch 232/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.3005 - val_loss: 2.6230\n",
      "Epoch 233/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2265 - val_loss: 4.1321\n",
      "Epoch 234/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2264 - val_loss: 2.4124\n",
      "Epoch 235/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2368 - val_loss: 2.4986\n",
      "Epoch 236/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2721 - val_loss: 5.5653\n",
      "Epoch 237/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2449 - val_loss: 2.2720\n",
      "Epoch 238/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3007 - val_loss: 3.3273\n",
      "Epoch 239/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.5445 - val_loss: 9.4068\n",
      "Epoch 240/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2267 - val_loss: 2.2444\n",
      "Epoch 241/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1759 - val_loss: 2.3789\n",
      "Epoch 242/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2277 - val_loss: 4.4656\n",
      "Epoch 243/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2772 - val_loss: 8.6580\n",
      "Epoch 244/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.3040 - val_loss: 2.9486\n",
      "Epoch 245/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.1794 - val_loss: 5.5594\n",
      "Epoch 246/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2477 - val_loss: 11.6522\n",
      "Epoch 247/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.3287 - val_loss: 6.9405 0s - loss: 0.32\n",
      "Epoch 248/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2755 - val_loss: 3.2487\n",
      "Epoch 249/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.1989 - val_loss: 2.5667\n",
      "Epoch 250/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2002 - val_loss: 2.9974\n",
      "Epoch 251/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2355 - val_loss: 3.0257\n",
      "Epoch 252/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2451 - val_loss: 3.8109\n",
      "Epoch 253/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3618 - val_loss: 3.4912\n",
      "Epoch 254/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2848 - val_loss: 2.8301\n",
      "Epoch 255/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2268 - val_loss: 4.3217\n",
      "Epoch 256/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2285 - val_loss: 4.0788\n",
      "Epoch 257/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2969 - val_loss: 2.6569\n",
      "Epoch 258/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1715 - val_loss: 2.5737\n",
      "Epoch 259/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1691 - val_loss: 3.1570\n",
      "Epoch 260/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2624 - val_loss: 7.5791\n",
      "Epoch 261/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3798 - val_loss: 4.4473\n",
      "Epoch 262/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2778 - val_loss: 2.5968\n",
      "Epoch 263/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1876 - val_loss: 3.0230\n",
      "Epoch 264/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2277 - val_loss: 3.7424\n",
      "Epoch 265/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.4135 - val_loss: 5.7748\n",
      "Epoch 266/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2639 - val_loss: 2.6864\n",
      "Epoch 267/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1730 - val_loss: 2.8736\n",
      "Epoch 268/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2079 - val_loss: 4.4071\n",
      "Epoch 269/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1798 - val_loss: 6.6186\n",
      "Epoch 270/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1958 - val_loss: 3.9684\n",
      "Epoch 271/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1882 - val_loss: 2.2676\n",
      "Epoch 272/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2417 - val_loss: 2.9067\n",
      "Epoch 273/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2339 - val_loss: 3.0432\n",
      "Epoch 274/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1855 - val_loss: 2.6851\n",
      "Epoch 275/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.3042 - val_loss: 5.8483\n",
      "Epoch 276/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1990 - val_loss: 3.1185\n",
      "Epoch 277/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1346 - val_loss: 2.3098\n",
      "Epoch 278/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2018 - val_loss: 5.7363\n",
      "Epoch 279/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1959 - val_loss: 2.3444\n",
      "Epoch 280/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1803 - val_loss: 2.2956\n",
      "Epoch 281/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2500 - val_loss: 2.1232\n",
      "Epoch 282/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1553 - val_loss: 3.7673\n",
      "Epoch 283/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2801 - val_loss: 2.4012\n",
      "Epoch 284/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1513 - val_loss: 2.8182\n",
      "Epoch 285/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2689 - val_loss: 3.9461\n",
      "Epoch 286/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.1822 - val_loss: 3.7368\n",
      "Epoch 287/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2969 - val_loss: 4.9560\n",
      "Epoch 288/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1815 - val_loss: 2.2970\n",
      "Epoch 289/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.1720 - val_loss: 2.3347\n",
      "Epoch 290/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2693 - val_loss: 2.7066\n",
      "Epoch 291/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2083 - val_loss: 4.2020\n",
      "Epoch 292/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.1896 - val_loss: 2.6810\n",
      "Epoch 293/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2231 - val_loss: 3.3816\n",
      "Epoch 294/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.1814 - val_loss: 2.2002\n",
      "Epoch 295/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2301 - val_loss: 2.1403\n",
      "Epoch 296/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1525 - val_loss: 2.3709\n",
      "Epoch 297/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1436 - val_loss: 2.4562\n",
      "Epoch 298/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1532 - val_loss: 2.5593\n",
      "Epoch 299/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.1929 - val_loss: 3.9263\n",
      "Epoch 300/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1855 - val_loss: 3.5386\n",
      "Epoch 301/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1820 - val_loss: 2.6277\n",
      "Epoch 302/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2269 - val_loss: 2.7896\n",
      "Epoch 303/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2192 - val_loss: 4.3041\n",
      "Epoch 304/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.2180 - val_loss: 3.5279\n",
      "Epoch 305/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1668 - val_loss: 2.0780\n",
      "Epoch 306/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.1928 - val_loss: 2.0893\n",
      "Epoch 307/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2242 - val_loss: 2.7055\n",
      "Epoch 308/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2134 - val_loss: 1.8911\n",
      "Epoch 309/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.1982 - val_loss: 2.4498\n",
      "Epoch 310/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1805 - val_loss: 4.2101\n",
      "Epoch 311/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3030 - val_loss: 4.2406\n",
      "Epoch 312/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2276 - val_loss: 2.4392\n",
      "Epoch 313/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.1509 - val_loss: 2.6279\n",
      "Epoch 314/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2760 - val_loss: 2.6086\n",
      "Epoch 315/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.1876 - val_loss: 2.0764\n",
      "Epoch 316/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1711 - val_loss: 8.1528\n",
      "Epoch 317/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2283 - val_loss: 2.1114\n",
      "Epoch 318/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.4938 - val_loss: 2.8968\n",
      "Epoch 319/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1903 - val_loss: 3.1280\n",
      "Epoch 320/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1601 - val_loss: 2.0181\n",
      "Epoch 321/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2032 - val_loss: 2.7073\n",
      "Epoch 322/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1588 - val_loss: 2.0641\n",
      "Epoch 323/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1866 - val_loss: 2.7270\n",
      "Epoch 324/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1841 - val_loss: 2.7688\n",
      "Epoch 325/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1409 - val_loss: 2.4909\n",
      "Epoch 326/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1533 - val_loss: 1.9916\n",
      "Epoch 327/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2168 - val_loss: 2.1802\n",
      "Epoch 328/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2714 - val_loss: 2.8585\n",
      "Epoch 329/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2551 - val_loss: 2.2691\n",
      "Epoch 330/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2234 - val_loss: 6.9810\n",
      "Epoch 331/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.4018 - val_loss: 3.1498\n",
      "Epoch 332/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1693 - val_loss: 2.2038\n",
      "Epoch 333/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1758 - val_loss: 2.7596\n",
      "Epoch 334/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.1447 - val_loss: 2.0524\n",
      "Epoch 335/500\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.1502 - val_loss: 2.7988\n",
      "Epoch 336/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2222 - val_loss: 3.4169\n",
      "Epoch 337/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.1634 - val_loss: 3.4464\n",
      "Epoch 338/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.1654 - val_loss: 4.9848\n",
      "Epoch 339/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2420 - val_loss: 2.4161\n",
      "Epoch 340/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1945 - val_loss: 3.5688\n",
      "Epoch 341/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1780 - val_loss: 2.0833\n",
      "Epoch 342/500\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.226 - 1s 20ms/step - loss: 0.2260 - val_loss: 2.3825\n",
      "Epoch 343/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3030 - val_loss: 2.2091\n",
      "Epoch 344/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2425 - val_loss: 2.7167\n",
      "Epoch 345/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1277 - val_loss: 2.3649\n",
      "Epoch 346/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1945 - val_loss: 2.1131\n",
      "Epoch 347/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1994 - val_loss: 2.5998\n",
      "Epoch 348/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1541 - val_loss: 1.8034\n",
      "Epoch 349/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1524 - val_loss: 3.9691\n",
      "Epoch 350/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1867 - val_loss: 1.7688\n",
      "Epoch 351/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1983 - val_loss: 2.6044\n",
      "Epoch 352/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1615 - val_loss: 1.7264\n",
      "Epoch 353/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1982 - val_loss: 1.9402\n",
      "Epoch 354/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2103 - val_loss: 2.3831\n",
      "Epoch 355/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2350 - val_loss: 1.9228\n",
      "Epoch 356/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2740 - val_loss: 4.0248\n",
      "Epoch 357/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2010 - val_loss: 3.0690\n",
      "Epoch 358/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1441 - val_loss: 2.1259\n",
      "Epoch 359/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1310 - val_loss: 2.1088\n",
      "Epoch 360/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1569 - val_loss: 2.4897\n",
      "Epoch 361/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1533 - val_loss: 1.9006\n",
      "Epoch 362/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1334 - val_loss: 1.9934\n",
      "Epoch 363/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1934 - val_loss: 3.2700\n",
      "Epoch 364/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2322 - val_loss: 11.6566\n",
      "Epoch 365/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.3033 - val_loss: 2.0216\n",
      "Epoch 366/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1530 - val_loss: 5.8429\n",
      "Epoch 367/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.3573 - val_loss: 3.0873\n",
      "Epoch 368/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.6651 - val_loss: 4.4780\n",
      "Epoch 369/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2463 - val_loss: 2.0964\n",
      "Epoch 370/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1989 - val_loss: 2.2412\n",
      "Epoch 371/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1907 - val_loss: 2.3598\n",
      "Epoch 372/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2580 - val_loss: 2.6957\n",
      "Epoch 373/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2376 - val_loss: 2.3324\n",
      "Epoch 374/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1574 - val_loss: 2.3537\n",
      "Epoch 375/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1668 - val_loss: 1.9522\n",
      "Epoch 376/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1628 - val_loss: 2.8068\n",
      "Epoch 377/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1501 - val_loss: 2.3083\n",
      "Epoch 378/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2188 - val_loss: 4.3551\n",
      "Epoch 379/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2143 - val_loss: 2.1635\n",
      "Epoch 380/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1278 - val_loss: 1.8696\n",
      "Epoch 381/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1122 - val_loss: 1.8809\n",
      "Epoch 382/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.1364 - val_loss: 2.1590\n",
      "Epoch 383/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1363 - val_loss: 2.0907\n",
      "Epoch 384/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1367 - val_loss: 1.9916\n",
      "Epoch 385/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1489 - val_loss: 3.3943\n",
      "Epoch 386/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1530 - val_loss: 1.8913\n",
      "Epoch 387/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1346 - val_loss: 2.0868\n",
      "Epoch 388/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1712 - val_loss: 1.8184\n",
      "Epoch 389/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1591 - val_loss: 2.7122\n",
      "Epoch 390/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2512 - val_loss: 2.4812\n",
      "Epoch 391/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2638 - val_loss: 2.3416\n",
      "Epoch 392/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2220 - val_loss: 2.0939\n",
      "Epoch 393/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1129 - val_loss: 1.7749\n",
      "Epoch 394/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1415 - val_loss: 2.1930\n",
      "Epoch 395/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1231 - val_loss: 2.0293\n",
      "Epoch 396/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1585 - val_loss: 4.7217\n",
      "Epoch 397/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2000 - val_loss: 4.3004\n",
      "Epoch 398/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2445 - val_loss: 2.4213\n",
      "Epoch 399/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1496 - val_loss: 3.9748\n",
      "Epoch 400/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1263 - val_loss: 1.8152\n",
      "Epoch 401/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1400 - val_loss: 2.5593\n",
      "Epoch 402/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1558 - val_loss: 10.6845\n",
      "Epoch 403/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1597 - val_loss: 4.0091\n",
      "Epoch 404/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1385 - val_loss: 1.8966\n",
      "Epoch 405/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1762 - val_loss: 3.8936\n",
      "Epoch 406/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2993 - val_loss: 2.0154\n",
      "Epoch 407/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2303 - val_loss: 2.1783\n",
      "Epoch 408/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2085 - val_loss: 2.5783\n",
      "Epoch 409/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1512 - val_loss: 1.9153\n",
      "Epoch 410/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1222 - val_loss: 2.3136\n",
      "Epoch 411/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.3682 - val_loss: 7.5311\n",
      "Epoch 412/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.3329 - val_loss: 2.5148\n",
      "Epoch 413/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1366 - val_loss: 1.9039\n",
      "Epoch 414/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1530 - val_loss: 3.3978\n",
      "Epoch 415/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.3413 - val_loss: 3.3234\n",
      "Epoch 416/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1806 - val_loss: 3.2224\n",
      "Epoch 417/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1843 - val_loss: 1.9940\n",
      "Epoch 418/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1664 - val_loss: 1.6393\n",
      "Epoch 419/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1442 - val_loss: 1.9758\n",
      "Epoch 420/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2181 - val_loss: 8.6168\n",
      "Epoch 421/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1480 - val_loss: 2.1745\n",
      "Epoch 422/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1256 - val_loss: 1.9295\n",
      "Epoch 423/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1603 - val_loss: 1.9245\n",
      "Epoch 424/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1977 - val_loss: 2.4137\n",
      "Epoch 425/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2602 - val_loss: 2.2891\n",
      "Epoch 426/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1565 - val_loss: 2.3132\n",
      "Epoch 427/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1349 - val_loss: 2.5896\n",
      "Epoch 428/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1942 - val_loss: 4.5755\n",
      "Epoch 429/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.5202 - val_loss: 3.4491\n",
      "Epoch 430/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2030 - val_loss: 2.8884\n",
      "Epoch 431/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1277 - val_loss: 4.1789\n",
      "Epoch 432/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1680 - val_loss: 2.5915\n",
      "Epoch 433/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1879 - val_loss: 7.8984\n",
      "Epoch 434/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2141 - val_loss: 3.6446\n",
      "Epoch 435/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1766 - val_loss: 2.0834\n",
      "Epoch 436/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1201 - val_loss: 4.2433\n",
      "Epoch 437/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2264 - val_loss: 3.0040\n",
      "Epoch 438/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1378 - val_loss: 1.5496\n",
      "Epoch 439/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1480 - val_loss: 1.8649\n",
      "Epoch 440/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1039 - val_loss: 1.6506\n",
      "Epoch 441/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1301 - val_loss: 2.0160\n",
      "Epoch 442/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1648 - val_loss: 2.0017\n",
      "Epoch 443/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1412 - val_loss: 3.0803\n",
      "Epoch 444/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2454 - val_loss: 4.7846\n",
      "Epoch 445/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.3579 - val_loss: 17.2062\n",
      "Epoch 446/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.3174 - val_loss: 2.2523\n",
      "Epoch 447/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2395 - val_loss: 1.7990\n",
      "Epoch 448/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2147 - val_loss: 2.4470\n",
      "Epoch 449/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2230 - val_loss: 1.8296\n",
      "Epoch 450/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.1519 - val_loss: 1.9083\n",
      "Epoch 451/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1467 - val_loss: 3.1380\n",
      "Epoch 452/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1615 - val_loss: 1.7769\n",
      "Epoch 453/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1836 - val_loss: 1.9723\n",
      "Epoch 454/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1328 - val_loss: 2.2356\n",
      "Epoch 455/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1496 - val_loss: 3.7519\n",
      "Epoch 456/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1344 - val_loss: 2.1824\n",
      "Epoch 457/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1579 - val_loss: 4.3485\n",
      "Epoch 458/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2387 - val_loss: 1.7549\n",
      "Epoch 459/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1293 - val_loss: 1.9231\n",
      "Epoch 460/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1850 - val_loss: 2.9829\n",
      "Epoch 461/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1613 - val_loss: 3.0980\n",
      "Epoch 462/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2141 - val_loss: 2.4897\n",
      "Epoch 463/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1762 - val_loss: 2.5734\n",
      "Epoch 464/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2482 - val_loss: 5.2708\n",
      "Epoch 465/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1542 - val_loss: 4.0298\n",
      "Epoch 466/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.2139 - val_loss: 3.5326\n",
      "Epoch 467/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1451 - val_loss: 2.3297\n",
      "Epoch 468/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.1923 - val_loss: 1.5323\n",
      "Epoch 469/500\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.1251 - val_loss: 1.9695\n",
      "Epoch 470/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1384 - val_loss: 4.0374\n",
      "Epoch 471/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1412 - val_loss: 1.5551\n",
      "Epoch 472/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1185 - val_loss: 2.6538\n",
      "Epoch 473/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1591 - val_loss: 1.7485\n",
      "Epoch 474/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1142 - val_loss: 2.3002\n",
      "Epoch 475/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1106 - val_loss: 2.2134\n",
      "Epoch 476/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1347 - val_loss: 1.8290\n",
      "Epoch 477/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1464 - val_loss: 2.2552\n",
      "Epoch 478/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1973 - val_loss: 4.8387\n",
      "Epoch 479/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.2590 - val_loss: 3.0397\n",
      "Epoch 480/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2762 - val_loss: 1.6981\n",
      "Epoch 481/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2268 - val_loss: 4.6511\n",
      "Epoch 482/500\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.2244 - val_loss: 5.4116\n",
      "Epoch 483/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.4620 - val_loss: 5.2374\n",
      "Epoch 484/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1807 - val_loss: 2.3626\n",
      "Epoch 485/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1600 - val_loss: 1.8266\n",
      "Epoch 486/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1728 - val_loss: 2.3906\n",
      "Epoch 487/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1891 - val_loss: 4.5053\n",
      "Epoch 488/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1382 - val_loss: 1.7018\n",
      "Epoch 489/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.2001 - val_loss: 3.5633\n",
      "Epoch 490/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1593 - val_loss: 4.8207\n",
      "Epoch 491/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1607 - val_loss: 2.0387\n",
      "Epoch 492/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1010 - val_loss: 2.6865\n",
      "Epoch 493/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.0966 - val_loss: 1.8441\n",
      "Epoch 494/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1347 - val_loss: 1.7263\n",
      "Epoch 495/500\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.1127 - val_loss: 1.7858\n",
      "Epoch 496/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1353 - val_loss: 1.5854\n",
      "Epoch 497/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1131 - val_loss: 1.7342\n",
      "Epoch 498/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1045 - val_loss: 1.9805\n",
      "Epoch 499/500\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.1558 - val_loss: 1.9159\n",
      "Epoch 500/500\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.1585 - val_loss: 1.8383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a0681d5df0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 500, batch_size = 64, verbose = 1, validation_data = (X_test, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bd21dce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 5, 3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dd53b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test,verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0e00cc5a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[120.935295]\n",
      " [119.70584 ]\n",
      " [117.39293 ]\n",
      " [117.83385 ]\n",
      " [118.32146 ]\n",
      " [115.738754]\n",
      " [114.91592 ]\n",
      " [115.2713  ]\n",
      " [116.37172 ]\n",
      " [112.65317 ]\n",
      " [115.41146 ]\n",
      " [109.48919 ]\n",
      " [109.00764 ]\n",
      " [111.31626 ]\n",
      " [114.798294]\n",
      " [119.42301 ]\n",
      " [118.48929 ]\n",
      " [118.98064 ]\n",
      " [116.290855]\n",
      " [118.70326 ]\n",
      " [119.823616]\n",
      " [118.9189  ]\n",
      " [120.115616]\n",
      " [120.39923 ]\n",
      " [119.31917 ]\n",
      " [118.04835 ]\n",
      " [117.809555]\n",
      " [115.0573  ]\n",
      " [114.26068 ]\n",
      " [116.45453 ]\n",
      " [117.36149 ]\n",
      " [120.07028 ]\n",
      " [122.74166 ]\n",
      " [123.023056]\n",
      " [123.438194]\n",
      " [122.696045]\n",
      " [124.42267 ]\n",
      " [124.723816]\n",
      " [124.01031 ]\n",
      " [123.13166 ]\n",
      " [122.26785 ]\n",
      " [122.44493 ]\n",
      " [127.20422 ]\n",
      " [128.56003 ]\n",
      " [130.0389  ]\n",
      " [128.46432 ]\n",
      " [127.39954 ]\n",
      " [132.35158 ]\n",
      " [132.35524 ]\n",
      " [133.12065 ]\n",
      " [135.05116 ]\n",
      " [135.31557 ]\n",
      " [133.84499 ]\n",
      " [133.26703 ]\n",
      " [129.88861 ]\n",
      " [130.88762 ]\n",
      " [130.99974 ]\n",
      " [130.39444 ]\n",
      " [132.03227 ]\n",
      " [130.29393 ]\n",
      " [129.43378 ]\n",
      " [131.00082 ]\n",
      " [130.81468 ]\n",
      " [129.60492 ]\n",
      " [128.99036 ]\n",
      " [131.852   ]\n",
      " [135.71388 ]\n",
      " [136.18687 ]\n",
      " [136.8816  ]\n",
      " [137.30144 ]\n",
      " [137.78987 ]\n",
      " [135.7257  ]\n",
      " [132.01903 ]\n",
      " [132.44167 ]\n",
      " [134.59018 ]\n",
      " [134.201   ]\n",
      " [134.87172 ]\n",
      " [135.39754 ]\n",
      " [135.04396 ]\n",
      " [135.42004 ]\n",
      " [134.73222 ]\n",
      " [134.09627 ]\n",
      " [134.24821 ]\n",
      " [133.97786 ]\n",
      " [130.97827 ]\n",
      " [129.61531 ]\n",
      " [130.24986 ]\n",
      " [128.8223  ]\n",
      " [122.953415]\n",
      " [124.09587 ]\n",
      " [123.9734  ]\n",
      " [123.30849 ]\n",
      " [127.34342 ]\n",
      " [127.12434 ]\n",
      " [124.58807 ]\n",
      " [121.79977 ]\n",
      " [119.592865]\n",
      " [117.88696 ]\n",
      " [121.121704]\n",
      " [121.39253 ]\n",
      " [122.48826 ]\n",
      " [120.811386]\n",
      " [122.87226 ]\n",
      " [126.72862 ]\n",
      " [125.28984 ]\n",
      " [121.894646]\n",
      " [121.20078 ]\n",
      " [122.891174]\n",
      " [123.55698 ]\n",
      " [121.63821 ]\n",
      " [120.856636]\n",
      " [120.57776 ]\n",
      " [121.842834]\n",
      " [119.883545]\n",
      " [122.79605 ]\n",
      " [123.97182 ]\n",
      " [125.78603 ]\n",
      " [127.3266  ]\n",
      " [128.05185 ]\n",
      " [130.41643 ]\n",
      " [132.69328 ]\n",
      " [132.25966 ]\n",
      " [133.74216 ]\n",
      " [133.33119 ]\n",
      " [134.06032 ]\n",
      " [134.15587 ]\n",
      " [134.14043 ]\n",
      " [133.49063 ]\n",
      " [132.59256 ]\n",
      " [133.24019 ]\n",
      " [133.87675 ]\n",
      " [134.11302 ]\n",
      " [134.25014 ]\n",
      " [133.87184 ]\n",
      " [134.0564  ]\n",
      " [132.6071  ]\n",
      " [133.61687 ]\n",
      " [129.08142 ]\n",
      " [129.61662 ]\n",
      " [130.12563 ]\n",
      " [130.76566 ]\n",
      " [129.15388 ]\n",
      " [125.85931 ]\n",
      " [124.44267 ]\n",
      " [125.59543 ]\n",
      " [127.73624 ]\n",
      " [126.82082 ]\n",
      " [126.74402 ]\n",
      " [125.11226 ]\n",
      " [127.58327 ]\n",
      " [127.10941 ]\n",
      " [128.17867 ]\n",
      " [128.55156 ]\n",
      " [127.742294]\n",
      " [127.64285 ]\n",
      " [125.830185]\n",
      " [125.54598 ]\n",
      " [125.360176]\n",
      " [124.60797 ]\n",
      " [125.97371 ]\n",
      " [126.374664]\n",
      " [128.4819  ]\n",
      " [128.27483 ]\n",
      " [128.27989 ]\n",
      " [127.81827 ]\n",
      " [130.20546 ]\n",
      " [130.83871 ]\n",
      " [130.83733 ]\n",
      " [132.04681 ]\n",
      " [132.02733 ]\n",
      " [131.77809 ]\n",
      " [133.17558 ]\n",
      " [133.99644 ]\n",
      " [133.6588  ]\n",
      " [133.32304 ]]\n"
     ]
    }
   ],
   "source": [
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0a1858f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n"
     ]
    }
   ],
   "source": [
    "print(len(yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "53f432ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.410318302174305"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_rmse = np.sqrt(np.mean(((yhat - y_test) **2)))\n",
    "lstm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "74b5981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train = df.iloc[0:int(lstm_training_lata_len),:]\n",
    "lstm_valid = df.iloc[lstm_training_lata_len -56: ,:]\n",
    "#lstm_valid[\"Predictions\"] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9f96eef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-103-fff299eeee13>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lstm_valid[\"Predictions\"] = yhat\n"
     ]
    }
   ],
   "source": [
    "lstm_valid[\"Predictions\"] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "43932413",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.732143</td>\n",
       "      <td>14.607143</td>\n",
       "      <td>14.621429</td>\n",
       "      <td>14.686786</td>\n",
       "      <td>302220800.0</td>\n",
       "      <td>12.629209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.810000</td>\n",
       "      <td>14.617143</td>\n",
       "      <td>14.642857</td>\n",
       "      <td>14.765714</td>\n",
       "      <td>260022000.0</td>\n",
       "      <td>12.697079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.948214</td>\n",
       "      <td>14.738214</td>\n",
       "      <td>14.819643</td>\n",
       "      <td>14.929643</td>\n",
       "      <td>271269600.0</td>\n",
       "      <td>12.838044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.098214</td>\n",
       "      <td>14.972143</td>\n",
       "      <td>14.991786</td>\n",
       "      <td>15.085714</td>\n",
       "      <td>318292800.0</td>\n",
       "      <td>12.972249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.276786</td>\n",
       "      <td>15.048214</td>\n",
       "      <td>15.196429</td>\n",
       "      <td>15.061786</td>\n",
       "      <td>394024400.0</td>\n",
       "      <td>12.951672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>138.789993</td>\n",
       "      <td>134.339996</td>\n",
       "      <td>138.050003</td>\n",
       "      <td>134.869995</td>\n",
       "      <td>121047300.0</td>\n",
       "      <td>134.440399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>135.990005</td>\n",
       "      <td>133.399994</td>\n",
       "      <td>135.580002</td>\n",
       "      <td>133.720001</td>\n",
       "      <td>96452100.0</td>\n",
       "      <td>133.294067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>134.740005</td>\n",
       "      <td>131.720001</td>\n",
       "      <td>134.080002</td>\n",
       "      <td>132.690002</td>\n",
       "      <td>99116600.0</td>\n",
       "      <td>132.267349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>133.610001</td>\n",
       "      <td>126.760002</td>\n",
       "      <td>133.520004</td>\n",
       "      <td>129.410004</td>\n",
       "      <td>143301900.0</td>\n",
       "      <td>128.997803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>131.740005</td>\n",
       "      <td>128.429993</td>\n",
       "      <td>128.889999</td>\n",
       "      <td>131.009995</td>\n",
       "      <td>97664900.0</td>\n",
       "      <td>130.592697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2267 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            High         Low        Open       Close       Volume   Adj Close\n",
       "0      14.732143   14.607143   14.621429   14.686786  302220800.0   12.629209\n",
       "1      14.810000   14.617143   14.642857   14.765714  260022000.0   12.697079\n",
       "2      14.948214   14.738214   14.819643   14.929643  271269600.0   12.838044\n",
       "3      15.098214   14.972143   14.991786   15.085714  318292800.0   12.972249\n",
       "4      15.276786   15.048214   15.196429   15.061786  394024400.0   12.951672\n",
       "...          ...         ...         ...         ...          ...         ...\n",
       "2262  138.789993  134.339996  138.050003  134.869995  121047300.0  134.440399\n",
       "2263  135.990005  133.399994  135.580002  133.720001   96452100.0  133.294067\n",
       "2264  134.740005  131.720001  134.080002  132.690002   99116600.0  132.267349\n",
       "2265  133.610001  126.760002  133.520004  129.410004  143301900.0  128.997803\n",
       "2266  131.740005  128.429993  128.889999  131.009995   97664900.0  130.592697\n",
       "\n",
       "[2267 rows x 6 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7a88c876",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>117.000000</td>\n",
       "      <td>114.919998</td>\n",
       "      <td>115.279999</td>\n",
       "      <td>116.970001</td>\n",
       "      <td>100506900.0</td>\n",
       "      <td>116.396606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>125.180000</td>\n",
       "      <td>119.279999</td>\n",
       "      <td>120.059998</td>\n",
       "      <td>124.400002</td>\n",
       "      <td>240226800.0</td>\n",
       "      <td>123.790192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>125.389999</td>\n",
       "      <td>119.650002</td>\n",
       "      <td>125.269997</td>\n",
       "      <td>121.099998</td>\n",
       "      <td>262330500.0</td>\n",
       "      <td>120.506355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>123.029999</td>\n",
       "      <td>119.620003</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.190002</td>\n",
       "      <td>150712000.0</td>\n",
       "      <td>120.595924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>121.199997</td>\n",
       "      <td>118.150002</td>\n",
       "      <td>118.720001</td>\n",
       "      <td>120.709999</td>\n",
       "      <td>112559200.0</td>\n",
       "      <td>120.118271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>132.410004</td>\n",
       "      <td>129.210007</td>\n",
       "      <td>130.300003</td>\n",
       "      <td>132.300003</td>\n",
       "      <td>79663300.0</td>\n",
       "      <td>132.300003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>134.080002</td>\n",
       "      <td>131.619995</td>\n",
       "      <td>132.130005</td>\n",
       "      <td>133.979996</td>\n",
       "      <td>74783600.0</td>\n",
       "      <td>133.979996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>134.320007</td>\n",
       "      <td>133.229996</td>\n",
       "      <td>133.770004</td>\n",
       "      <td>133.699997</td>\n",
       "      <td>60214200.0</td>\n",
       "      <td>133.699997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>134.639999</td>\n",
       "      <td>132.929993</td>\n",
       "      <td>134.449997</td>\n",
       "      <td>133.410004</td>\n",
       "      <td>68711000.0</td>\n",
       "      <td>133.410004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>133.889999</td>\n",
       "      <td>132.809998</td>\n",
       "      <td>133.460007</td>\n",
       "      <td>133.110001</td>\n",
       "      <td>70730700.0</td>\n",
       "      <td>133.110001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            High         Low        Open       Close       Volume   Adj Close\n",
       "2207  117.000000  114.919998  115.279999  116.970001  100506900.0  116.396606\n",
       "2208  125.180000  119.279999  120.059998  124.400002  240226800.0  123.790192\n",
       "2209  125.389999  119.650002  125.269997  121.099998  262330500.0  120.506355\n",
       "2210  123.029999  119.620003  121.000000  121.190002  150712000.0  120.595924\n",
       "2211  121.199997  118.150002  118.720001  120.709999  112559200.0  120.118271\n",
       "...          ...         ...         ...         ...          ...         ...\n",
       "2381  132.410004  129.210007  130.300003  132.300003   79663300.0  132.300003\n",
       "2382  134.080002  131.619995  132.130005  133.979996   74783600.0  133.979996\n",
       "2383  134.320007  133.229996  133.770004  133.699997   60214200.0  133.699997\n",
       "2384  134.639999  132.929993  134.449997  133.410004   68711000.0  133.410004\n",
       "2385  133.889999  132.809998  133.460007  133.110001   70730700.0  133.110001\n",
       "\n",
       "[179 rows x 6 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3c9183c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f2e99d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize= (16,6))\n",
    "plt.title('Modelimiz')\n",
    "plt.xlabel(\"Date\",fontsize = 18)\n",
    "plt.ylabel(\"Close USD $\", fontsize = 18)\n",
    "plt.plot(lstm_train[\"Close\"])\n",
    "plt.plot(lstm_valid[[\"Close\" , \"Predictions\"]])\n",
    "plt.legend([\"Train\", \"Val\", \"Predictions\"], loc = \"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17375a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc6402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8613a62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
